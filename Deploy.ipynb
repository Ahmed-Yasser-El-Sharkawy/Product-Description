{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"16ro6hLBQ_hcQ1-hPabOnTquWN2gt5Cwt","authorship_tag":"ABX9TyNj7rJEypOq9dfR/DiY97lF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E5cFXStitArP","executionInfo":{"status":"ok","timestamp":1728216356910,"user_tz":-180,"elapsed":12307,"user":{"displayName":"احمد ياسر عبدالله الشرقاوى","userId":"13524008368720307491"}},"outputId":"f1b8a901-8743-463f-93f9-c0dca9fa0471"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m854.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install streamlit pyngrok --quiet"]},{"cell_type":"code","source":[],"metadata":{"id":"8NpJBeJQuH_j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile app.py\n","import streamlit as st\n","from PIL import Image\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n","import numpy as np\n","\n","# Set device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Load the main classifier (Main_Classifier_best_model.pth)\n","main_model = models.resnet18(pretrained=False)\n","num_ftrs = main_model.fc.in_features\n","main_model.fc = nn.Linear(num_ftrs, 3)  # 3 classes: Soda drinks, Clothing, Mobile Phones\n","main_model.load_state_dict(torch.load('Main_Classifier_best_model.pth', map_location=device))\n","main_model = main_model.to(device)\n","main_model.eval()\n","\n","# Define class names for the main classifier based on folder structure\n","main_class_names = ['Clothing', 'Mobile Phones', 'Soda drinks']\n","\n","# Sub-classifier models\n","def load_soda_drinks_model():\n","    model = models.resnet18(pretrained=False)\n","    num_ftrs = model.fc.in_features\n","    model.fc = nn.Linear(num_ftrs, 3)  # 3 classes: Miranda, Pepsi, Seven Up\n","    model.load_state_dict(torch.load('Soda_drinks_best_model.pth', map_location=device))\n","    model = model.to(device)\n","    model.eval()\n","    return model\n","\n","def load_clothing_model():\n","    model = models.resnet18(pretrained=False)\n","    num_ftrs = model.fc.in_features\n","    model.fc = nn.Linear(num_ftrs, 2)  # 2 classes: Pants, T-Shirt\n","    model.load_state_dict(torch.load('Clothes_best_model.pth', map_location=device))\n","    model = model.to(device)\n","    model.eval()\n","    return model\n","\n","def load_mobile_phones_model():\n","    model = models.resnet18(pretrained=False)\n","    num_ftrs = model.fc.in_features\n","    model.fc = nn.Linear(num_ftrs, 2)  # 2 classes: Apple, Samsung\n","    model.load_state_dict(torch.load('Phone_best_model.pth', map_location=device))\n","    model = model.to(device)\n","    model.eval()\n","    return model\n","\n","def convert_to_rgb(image):\n","    \"\"\"\n","    Converts 'P' mode images with transparency to 'RGBA', and then to 'RGB'.\n","    This is to avoid transparency issues during model training.\n","    \"\"\"\n","    if image.mode in ('P', 'RGBA'):\n","        return image.convert('RGB')\n","    return image\n","\n","# Define preprocessing transformations (same used during training)\n","preprocess = transforms.Compose([\n","    transforms.Lambda(convert_to_rgb),\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet normalization\n","])\n","\n","# Streamlit App Interface\n","st.title(\"Main and Sub-Classifier System\")\n","st.write(\"Upload an image to classify whether it belongs to Clothing, Mobile Phones, or Soda Drinks. Based on the prediction, it will further classify within the subcategory.\")\n","\n","# Image uploader in Streamlit\n","uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n","\n","if uploaded_file is not None:\n","    # Open the image using PIL\n","    image = Image.open(uploaded_file)\n","\n","    # Display the uploaded image\n","    st.image(image, caption='Uploaded Image', use_column_width=True)\n","    st.write(\"\")\n","    st.write(\"Classifying...\")\n","\n","    # Preprocess the image\n","    input_image = preprocess(image).unsqueeze(0).to(device)\n","\n","    # Perform inference with the main classifier\n","    with torch.no_grad():\n","        output = main_model(input_image)\n","        probabilities = torch.nn.functional.softmax(output[0], dim=0)\n","        confidence, predicted_class = torch.max(probabilities, 0)\n","\n","    # Display the main classifier result\n","    main_prediction = main_class_names[predicted_class]\n","    st.write(f\"**Main Predicted Class:** {main_prediction}\")\n","    st.write(f\"**Confidence:** {confidence.item():.4f}\")\n","\n","    # Load and apply the sub-classifier based on the main classification\n","    if main_prediction == 'Soda drinks':\n","        st.write(\"Loading Soda Drinks Model...\")\n","        soda_model = load_soda_drinks_model()\n","        sub_class_names = ['Miranda', 'Pepsi', 'Seven Up']\n","    elif main_prediction == 'Clothing':\n","        st.write(\"Loading Clothing Model...\")\n","        clothing_model = load_clothing_model()\n","        sub_class_names = ['Pants', 'T-Shirt']\n","    elif main_prediction == 'Mobile Phones':\n","        st.write(\"Loading Mobile Phones Model...\")\n","        phones_model = load_mobile_phones_model()\n","        sub_class_names = ['Apple', 'Samsung']\n","\n","    # Perform inference with the sub-classifier\n","    with torch.no_grad():\n","        if main_prediction == 'Soda drinks':\n","            sub_output = soda_model(input_image)\n","        elif main_prediction == 'Clothing':\n","            sub_output = clothing_model(input_image)\n","        elif main_prediction == 'Mobile Phones':\n","            sub_output = phones_model(input_image)\n","\n","        sub_probabilities = torch.nn.functional.softmax(sub_output[0], dim=0)\n","        sub_confidence, sub_predicted_class = torch.max(sub_probabilities, 0)\n","\n","    # Display the sub-classifier result\n","    st.write(f\"**Sub Predicted Class:** {sub_class_names[sub_predicted_class]}\")\n","    st.write(f\"**Confidence:** {sub_confidence.item():.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wGUpwQ8rzq6X","executionInfo":{"status":"ok","timestamp":1728218805774,"user_tz":-180,"elapsed":334,"user":{"displayName":"احمد ياسر عبدالله الشرقاوى","userId":"13524008368720307491"}},"outputId":"dae8632f-1990-41c3-f4a8-576686389906"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing app.py\n"]}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9J5oMvVhzxvy","executionInfo":{"status":"ok","timestamp":1728218114402,"user_tz":-180,"elapsed":41814,"user":{"displayName":"احمد ياسر عبدالله الشرقاوى","userId":"13524008368720307491"}},"outputId":"11cffc6c-f574-467f-b31e-0b50841acb3c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["File copied from /content/drive/MyDrive/data/Final Project /Data.zip to /content/Data.zip\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"NTo9PyeP0plb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OAuSayPG0yY_"},"execution_count":null,"outputs":[]}]}